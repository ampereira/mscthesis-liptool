
\chapter{Introduction}

The Large Hardron Collider (LHC) \cite{CERN:LHC} is a high-energy particle accelerator, located in the underground of the border between Switzerland and France, built by the European Organization for Nuclear Research (CERN) \cite{CERN}. It results from a cooperation between many countries, involving thousands of scientists around the world. The LHC is used to conduct experiments to validate several high-energy physics (HEP) theories. Proving the existence of the Higgs boson is currently one of the most popular.

At the LHC, an experiment usually consists of a head-on collision of particles (which is considered an event), where detectors gather data about the collision. There are different detectors with different purposes, according to the experiments that they were built for, but usually capture information related to the particles resultant from the head-on collision, such as their mass, momentum and energy. There are six detectors spread along the LHC, where millions of particle collisions occur each second, generating massive amounts of data to process \cite{LIP:Ibergrid}.

The information gathered passes through a set of computational tiers, in which the data is refined and scattered among the distributed computational resources, until it is ready to be used in simulations by the research groups, where it is analyzed \cite{CERN:DATA}.

ATLAS \cite{CERN:ATLAS} is one of the main experiments being conducted at the LHC. The Laboratório de Instrumentação e Física Experimental de Partículas (LIP) \cite{LIP} is one of the research groups involved in supporting and analyzing the data of this experiment. LIP continuously performs analysis on the data gathered by the ATLAS detector, competing against other research groups, within the ATLAS project, in order to analyze the most data and be the first to publish relevant results.

The focus of this dissertation will be on tuning and parallelizing the kinematical reconstruction of events, using as case study a specific analysis application, the ttH\_dilep, developed by LIP. The kinematical reconstruction is very important for their research and, consequently, is widely used within the group. By using a case study, the work will not be restricted to only the kinematical reconstruction. Other application specific tasks will be analyzed to improve the performance their performance in order to (i) get the maximum efficiency from the tuned kinematical reconstruction, and (ii) improve the overall performance of the analysis.

The tuning of both the kinematical reconstruction and overall improvement of the application performance will be performed on heterogeneous architectures, which combine traditional all-around multicore processors with accelerator devices in the same system. Porting code that was original designed for sequential execution to these heterogeneous environments faces a series of challenges, such as different architectural and programming paradigms, tuning the code for specific devices (which requires great knowledge of the device architecture), and load balancing of the tasks between CPU and accelerators. The most efforts will be towards obtaining the most optimized implementation of the kinematical reconstruction possible for the heterogeneous platforms, specifically to run the kinematical reconstruction, and possibly other tasks, on accelerator devices. These platforms will be presented in section \ref{stateart}, with a special focus on the accelerator devices.

There are several frameworks that try to ease the burden of these challenges on the programmer. Usually, they attempt to create a level of abstraction between the architectural details of the heterogeneous environments, and consequently the programing paradigm, and the programming environment. The GAMA and OpenACC frameworks will be tested in the context of this problem, and the implementations using these frameworks will be compared to the optimized implementations mentioned previously, in terms of performance, usability and development time.

\newpage
