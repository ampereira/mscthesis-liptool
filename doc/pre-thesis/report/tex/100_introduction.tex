
\chapter{Introduction}

The Large Hardron Collider (LHC) \cite{CERN:LHC} is a high-energy particle accelerator, located in the underground in both sides of the border between Switzerland and France, built by the European Organization for Nuclear Research (CERN) \cite{CERN}. It results from a cooperation between many countries, involving thousands of scientists around the world. The LHC is used to conduct experiments to validate high-energy physics (HEP) theories. Proving the existence of the Higgs boson is currently one of the most popular.

At the LHC, an experiment usually refers to a head-on collision of particles (which is considered an event), where detectors gather data related to the collision. There are different detectors with different purposes according to the experiments that they were built for, but these usually capture information related to the particles resultant from the head-on collision, such as their mass, momentum and energy. There are six detectors spread along the LHC, where millions of particle collisions occur each second, generating massive amounts of data to process \cite{LIP:Ibergrid}.

The information gathered passes through a set of computational tiers, in which the data is refined and scattered among the distributed computational resources, until it is ready to be used in simulations by the research groups, where it is analyzed \cite{CERN:DATA}.

ATLAS \cite{CERN:ATLAS} is one of the main experiments being conducted at the LHC. The Laboratório de Instrumentação e Física Experimental de Partículas (LIP) \cite{LIP} is one of the research groups involved in supporting and analyzing the data of this experiment. LIP continuously performs analysis on the data gathered by the ATLAS detector, competing against other research groups, within the ATLAS project, to obtain and publish relevant results.

The focus of this dissertation will be on tuning and parallelizing the kinematical reconstruction of events, using as case study a specific analysis application, the \tth, developed by LIP. The kinematical reconstruction is widely used within the group, but the work will not be restricted to only the kinematical reconstruction. Other application specific tasks will be analyzed to improve their performance in order to (i) get the maximum efficiency from the tuned kinematical reconstruction, and (ii) improve the overall performance of the analysis.

The tuning of both the kinematical reconstruction and overall improvement of the application performance will address heterogeneous architectures, which combine conventional multicore processors with accelerator devices in the same system. Efficient porting from sequential execution to these heterogeneous environments places a series of challenges, such as different architectural and programming paradigms, and load balancing of the tasks and data between CPU and accelerators. The main efforts will be towards obtaining an optimized implementation of the kinematical reconstruction possible for the heterogeneous platforms, specifically to run the kinematical reconstruction, and possibly other tasks, on accelerator devices. These platforms will be presented in section \ref{stateart}, with a special focus on the accelerator devices.

There are several development frameworks that aim to ease the programmer burden of these challenges. Usually, they attempt to create a level of abstraction between the architectural details of the heterogeneous environments, and consequently the programing paradigm, and the programming environment. The GAMA and OpenACC frameworks will be tested in the context of this problem, and the implementations using these frameworks will be compared to the optimized implementations mentioned previously, in terms of performance, usability and development time.

\newpage
