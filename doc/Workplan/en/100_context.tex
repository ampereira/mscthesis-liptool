%!TEX root = ../workplan.tex
\section{Context}
\todoshaky{100 enquadramento}

The Large Hardron Collider (LHC) \cite{CERN:LHC} is high-energy particle accelerator, built by the European Organization for Nuclear Research (CERN) \cite{CERN}. The LHC is used by physicists to validate high-energy physics (HEP) theories by experiment. There are several experiments being conducted along the LHC, where detectors, with different configurations according to their experiment purposes, gather data relative to the head-on collision of particles, which is considered an event. This data is mostly related to the characteristics of the resultant particles of the collision, such as momentum, energy and mass. Millions of particle collisions occur each second at the LHC, generating a massive amounts of data by the detectors.

One of the most important experiments running on the LHC is ATLAS \cite{CERN:ATLAS}, which results from a collaboration of many research groups around the world. One of those groups is the Laboratório de Experimentação e Física Experimental de Partículas (LIP) \cite{LIP}, which, as the other groups, continuously performs analysis on the data gathered by the ATLAS detector. The ATLAS research groups compete against each other for being the first to publish relevant results, meaning that they want to analyze the most data possible within very strict time schedules.

An analysis consists of an application that executes a set of algorithms on the collected data, in order to extract valuable information, from the HEP perspective. Before being analyzed, the data is incrementally refined, where from each iteration results a different data format holding the information. Different formats are optimized for different purposes, but oriented by a write-once many-reads policy. The more refined the data is, the smaller its size \cite{CERN:ATLAS:DATA}.

Every analysis uses the ROOT framework \cite{CERN:ROOT}. It provides data structures and I/O functionality, oriented for some of the data formats, and statistical analysis and visualization of the application output. Moreover, it can build the skeleton of the analysis based on the input data, offers parallelization packages for shared and distributed memory systems and has libraries for linear algebra, numerical algorithms and other utilities.

Since the skeleton that ROOT creates for the analysis has some limitations, the LIP research group built one according to their specific needs, so that most of their analysis can take advantage of it. The objective is to accelerate the development of analysis, which must be as fast as possible to fit in the strict time schedules already mentioned. Each time an update must be done on a given analysis, there is little time to test and refine the implementation, causing the applications to be badly structured.

During the last year work has been done on one of the analysis, TTBAR\_Dilep, on the scope of Parallel and Distributed Computing curricular unit, exploring the potential of the kinematical reconstruction of events on various platforms. The objective was to run the kinematical reconstruction as many times as possible, per each event processed, within a reasonable time frame, which allows to process many events in such a way that enough results are obtained. Running the reconstruction many times allows overcoming the experimental resolution of the ATLAS detector, by being able to chose the most precise reconstructions, leading to more accurate results and better physics. Approaches using shared and distributed memory systems, as well as heterogeneous systems with manycore accelerating devices (GPUs in this case), were tested and compared in that work \cite{LIP:PI}.

Heterogeneous architectures offer a different approach than the traditional multicore architectures. An heterogeneous system combines the multicore processors with specialized manycore accelerator devices. They are constituted of smaller processing units, focused only on achieving the best performance possible on certain areas, as opposed to common CPUs. Their architecture strategy is oriented for massive data parallelism processing \cite{Hennessy:Patterson:2012:CAQA}, offloading the CPU from such data intensive operations. Several manycore accelerating devices are available, ranging from the general purpose GPUs, the \intel Many Integrated Core line, currently known as \intel Xeon Phi, and Digital Signal Processors \cite{NVIDIA:GPGPU, Intel:MIC, Texas:DSP}. A heterogeneous system may have one or more accelerating devices of the same or different types.

Different accelerating devices have different architectures, which affect the programming and tuning of the code to run on a specific device. Moreover, when combining the execution of an application on accelerating devices and regular CPUs, the load balancing becomes an important issue to manage. To optimize the resource usage, it is important to efficiently divide the workload, in such a way that neither the said devices nor the CPU becomes stalled for long periods of time. Tuning the code for different devices, which usually implies a whole new programming paradigm, and ensuring a efficient load balancing between multicore and manycore processors can become a complex task for the programmers to manage.

To ease this complexity to the programmer several frameworks were developed, addressing different domains of this subject. They differ from some SDKs as the latter is usually oriented to develop code for specific accelerating devices (such as \nvidia \cuda \cite{NVIDIA:CUDA}), than for the whole heterogeneous system. StarPU is a high-level system which schedules a graph of tasks onto a heterogeneous platform in runtime \cite{StarPU}. It hides the complexities of programming to an heterogeneous platform by managing the load distribution, which commonly is the most complex aspect to deal with on these platforms. The GPU And Multi-core Aware (GAMA) project is an alternative to StarPU being designed specifically for GPUs with \cuda, and also addresses irregular applications \cite{Barbosa:2012,Mariano:Alves:2012,Alves:2012}. OpenACC is also a high-level framework, similar to StarPU, which manages initialization, shutdown and work balance of CPU and various accelerating devices \cite{OpenACC}.

Neither ROOT nor the LIP framework offers the tools to run any portion of an application in heterogeneous systems with accelerating devices. As proved in last year work, the kinematical reconstruction was fastest when running on a GPU. Not much tuning of the code was performed, and many other approaches were not explored (as concurrently execute reconstructions on the CPU and GPU, and using other accelerating devices). Also, there are newer architectures of GPUs, namely Kepler \cite{NVIDIA:Kepler}, and other accelerating, as mentioned before, that could improve the overall performance of the application.
