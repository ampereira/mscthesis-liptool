
\pdfbookmark{Contents}{contents}
\tableofcontents

\newpage \pdfbookmark{Glossary}{glossary}
\chapter*{Glossary}
\begin{acronym}
  \acro{Event}{head-on collision between two particles at the LHC}
  \acro{LHC}{Large Hardron Collider particle accelerator}
  \acro{ATLAS project}{Experiment being conducted at the LHC with an associated particle detector}
  \acro{LIP}{Laboratório de Instrumentação e Física Experimental de Partículas, Portuguese research group working in the ATLAS project}
  \acro{CERN}{European Organization for Nuclear Research, which results from a collaboration from many countries to test HEP theories}
  \acro{HEP}{High Energy Physics}
  \acro{Analysis}{Application developed to process the data gathered by the ATLAS detector and test a specific HEP theory}
  \acro{Accelerator device}{Specialized processing unit connected to the system by a PCI-Express interface}
  \acro{CPU}{Central Processing Unit, which may contain one or more cores (multicore)}
  \acro{GPU}{Graphics Processing Unit}
  \acro{GPGPU}{General Purpose Graphics Processing Unit, recent designation to  scientific computing oriented GPUs}
  \acro{DSP}{Digital Signal Processor}
  \acro{MIC}{Many Integrated Core, accelerator device architecture developed by \intel, also known as Xeon Phi}
  \acro{QPI}{Quickpath Interconnect, point-to-point interconnection developed by \intel}
  \acro{HT}{HyperTransport, point-to-point interconnection developed by the HyperTransport Consortium}
  \acro{NUMA}{Non-Uniform Memory Access, memory design where the access time depends on the location of the memory relative to a processor}
  \acro{ISE}{Instruction Set Extensions, extensions to the CPU instruction set, usually SIMD}
  \acro{Homogeneous system}{Classic computer system, which contain one or more similar multicore CPUs}
  \acro{Heterogeneous system}{Computer system, which contains a multicore CPU and one or more accelerator devices}
  \acro{SIMD}{Single Instruction Multiple Data, describes a parallel processing architecture where a single instruction is applied to a large set of data simultaneously}
  \acro{SIMT}{Single Instruction Multiple Threads, describes the processing architecture that \nvidia uses, very similar to SIMD, where a thread is responsable for a subset of the data to process}
  \acro{SM/SMX}{Streaming Multiprocessor, SIMT/SIMD processing unit available in \nvidia GPUs}
  \acro{Kernel}{Parallel portion of an application code designed to run on a CUDA capable GPU}
  \acro{Host}{CPU in a heterogeneous system, using the CUDA designation}
  \acro{CUDA}{Compute Unified Device Architecture, a parallel computing platform for GPUs}
  \acro{OpenMP}{Open Multi-Processing, an API for shared memory multiprocessing}
  \acro{OpenACC}{Open Accelerator, an API to offload code from a host CPU to an attached accelerator}
  \acro{GAMA}{GPU and Multicore Aware, an API for shared memory multiprocessing in platforms with a host CPU and an attached CUDA enabled accelerators}
  \acro{Speedup}{Ratio of the performance increase between two versions of the code. Usually comparing single vs multithreaded applications.}
\end{acronym}

\newpage \pdfbookmark{List of Figures}{figures}
\listoffigures
\newpage
