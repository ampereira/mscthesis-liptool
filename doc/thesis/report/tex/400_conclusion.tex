\chapter{Conclusions \& Future Work}
\label{ConclusionFutureWork}

\begin{quote}
\textit{This chapter concludes the dissertation, presenting an overview of the results obtained by the work developed, on both homogeneous and heterogeneous systems. Guidelines for future work, on improving the test case application and providing parallel solutions abstracted from the programmer for future application development, are presented.}
\end{quote}

\section{Conclusions}
\label{Conclusion}

This dissertation presents 4 different approaches to increase the performance of a scientific application that processes event data gathered by the ATLAS project at CERN, using homogeneous and heterogeneous systems, the latter with 2 different computing accelerators. The main goal was to evaluate the usability, performance and efficiency of the different systems and specific accelerators, as well as the structure of the physics application and libraries.

The scientific application attempts to reconstruct the top quarks and Higgs boson that decay from a head-on collision of two protons, based on the resultant data collected in the ATLAS particle detector at the LHC. The quality of the reconstruction depends on the amount of partial reconstructions performed, where the event parameters are slightly varied, to overcome the experimental resolution of the particle detector and find the most accurate final reconstruction. Increasing the number of partial reconstructions directly affects the application execution time, decreasing the number of events processed per time unit and impacting the research conducted by LIP.

Having identified the pseudo-random number generator as a key resource consumer of the application, the first optimization techniques were here applied. Then, 4 parallel implementation solutions were developed, based on an identification of the critical region limiting the performance. Two implementations target heterogeneous systems with accelerator devices, one using an \nvidia GPU and other using the \intel Xeon Phi. Both implementations face many limitations, primarly due to the lack of a data structure holding all the event information on both the application and LipMiniAnalysis, restricting the performance gains and efficient use of the GPU. Also, due to these hardware limitations, only part of the application critical region was parallelized on the accelerator, increasing the amount of high latency memory transfers between CPU and GPU, and forcing the rest to be parallelized on the CPU.

The parallelization on the \intel Xeon Phi aimed to evaluate its performance, but more importantly, its usability, as \intel advertises easy porting of CPU code to the device. The goal was to test the Xeon Phi in both native and offload modes. One of the application dependencies is the ROOT library developed by CERN that was supposed to have support for this device did not work and many hours were spent trying to solve the problem. Using the device in offload mode, similar to the GPU, would require that only part of the critical region is parallelized, as it depends on many functionalities of ROOT that cannot be simultaneously compiled for CPU and Xeon Phi. Its resources would also be inefficiently used due to the lack of a global data structure with all events. Even though the parallelization implementation is simplified by the use of pragma directives available for this device, the driver offered many limitations due to the computational complexity of the portion of the code to parallelize. The Xeon Phi is still new to the market, causing its drivers and libraries to not be completely stable. Many of the errors provided by the drivers were not even documented yet. Due to the dissertation timeframe, both implementations were left on hold, with the only conclusion that the device is not mature enough to provide an easy porting of the code for real applications, opposed to \intel claims.

The remaining 2 parallel implementations were aimed towards homogeneous systems, which constitute all of the LIP computational resources. The first was a shared memory implementation, from which two versions derived. One has a smaller parallelization overhead and better performance on single-socket systems, while the second, with a larger overhead, performs better on multi-socket systems. The second implementation is an application scheduler, oriented for multi-socket systems. The idea was based on the efficient use of computational resources of the first version of the shared memory implementation on a single CPU. Multiple instances of this application, processing different input data files, would provide an efficient use of all available computational resources and an even bigger increase in performance, compared to the shared memory implementations. A prototype was developed and tested with promissing results, but its performance is still manually tuned by a set of parameters which may vary from system to system. The scheduler is prepared to work with any kind of scientific application, only requiring that multithreaded applications use a given API to be configured.

The lack of structure on the code of both the application and LipMiniAnalysis library restricted the performance on heterogeneous systems. The best performance was attained for a shared memory implementation on homogeneous systems and, allied to the use of a prototype scheduler, provided an efficient use of the available resources. The LIP research group has the best interest in these implementations as they increase their productivity and do not require investment in expensive hardware accelerators.

\section{Future Work}
\label{FutureWork}

The results obtained in this dissertation, specially for the implementations on heterogeneous systems and the application scheduler, motivates further work on this theme. The application scheduler is on the best interest of the LIP research group and, if its development continues, it may be widely used among the researchers. Guidelines for continuing this dissertation work may include:

\begin{itemize}
	\item Restructure the LipMiniAnalysis library, creating a data structure holding all the event information in the input data file. These files are usually 1 GB size, which is perfectly capable of being stored in RAM memory. It would allow a more efficient implementation of this kind of applications on heterogeneous systems with hardware accelerators.
	\item Refine the GPU implementation using the new restructured version of LipMiniAnalysis and analyse if the potential performance gains justify investment from the LIP group on this hardware and train human resources to program for these devices.
	\item Explore parallelism on heterogeneous systems using parallelization frameworks, such as OpenACC.
	\item Refine the application scheduler prototype by:
	\begin{itemize}
		\item Implementing and validating the remaining features for working with any kind of scientific application;
		\item Validating its capability of scheduling different applications on the same system;
		\item Overall load balancing optimizations by refining current mechanisms, such as implementing specific core binding of the applications;
		\item Implementing micro-benchmarks to evaluate the computational system and generate the best setup, considering the computational characteristics of these applications.
	\end{itemize}
	\item Parallelization of the restructured LipMiniAnalysis. Since the library serves as a skeleton for many of the LIP applications, a parallelization at the event level would allow high performance and efficient applications to be developed by physicists without requiring the programming know-how to extract parallelism on homogeneous platforms.
\end{itemize}
